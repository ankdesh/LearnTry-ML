{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        ## Conv Layers\n",
    "        self.conv_l1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
    "        self.bn_l1 = nn.BatchNorm2d(16)\n",
    "            \n",
    "        self.conv_l2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
    "        self.bn_l2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_l3 = nn.Conv2d(in_channels=32, out_channels=48, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
    "        self.bn_l3 = nn.BatchNorm2d(48)\n",
    "        \n",
    "        self.conv_l4 = nn.Conv2d(in_channels=48, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
    "        self.bn_l4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_l5 = nn.Conv2d(in_channels=64, out_channels=80, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
    "        self.bn_l5 = nn.BatchNorm2d(80)\n",
    "        \n",
    "        self.leakyRelu = torch.nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.lstm_l1 = torch.nn.LSTM(input_size=1280, hidden_size=256, batch_first=True, bidirectional=True, num_layers=5)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        ## Conv Layers \n",
    "        x = self.conv_l1(x)\n",
    "        x = self.bn_l1(x)\n",
    "        x = self.leakyRelu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv_l2(x)\n",
    "        x = self.bn_l2(x)\n",
    "        x = self.leakyRelu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.conv_l3(x)\n",
    "        x = self.bn_l3(x)\n",
    "        x = self.leakyRelu(x)\n",
    "        x = self.pool(x)\n",
    "                \n",
    "        x = self.dropout(x)\n",
    "        x = self.conv_l4(x)\n",
    "        x = self.bn_l4(x)\n",
    "        x = self.leakyRelu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.conv_l5(x)\n",
    "        x = self.bn_l5(x)\n",
    "        x = self.leakyRelu(x)\n",
    "        \n",
    "        ## LSTM\n",
    "        x = x.view(1, 128, -1)\n",
    "        #batch_size, num_channels, input_size = x.shape\n",
    "        #print (batch_size, num_channels, input_size)\n",
    "        #print (type(x))\n",
    "        \n",
    "        h0 = torch.randn(5*2, 1, 256).to(\"cuda\")\n",
    "        c0 = torch.randn(5*2, 1, 256).to(\"cuda\")\n",
    "        \n",
    "        x,(hn,cn) = self.lstm_l1(x,(h0,c0))\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam (self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "                Kernel Shape        Output Shape     Params    Mult-Adds\n",
      "Layer                                                                   \n",
      "0_conv_l1      [1, 16, 3, 3]  [1, 16, 1024, 128]      160.0   18.874368M\n",
      "1_bn_l1                 [16]  [1, 16, 1024, 128]       32.0         16.0\n",
      "2_leakyRelu                -  [1, 16, 1024, 128]          -            -\n",
      "3_pool                     -    [1, 16, 512, 64]          -            -\n",
      "4_conv_l2     [16, 32, 3, 3]    [1, 32, 512, 64]      4.64k  150.994944M\n",
      "5_bn_l2                 [32]    [1, 32, 512, 64]       64.0         32.0\n",
      "6_leakyRelu                -    [1, 32, 512, 64]          -            -\n",
      "7_pool                     -    [1, 32, 256, 32]          -            -\n",
      "8_dropout                  -    [1, 32, 256, 32]          -            -\n",
      "9_conv_l3     [32, 48, 3, 3]    [1, 48, 256, 32]    13.872k  113.246208M\n",
      "10_bn_l3                [48]    [1, 48, 256, 32]       96.0         48.0\n",
      "11_leakyRelu               -    [1, 48, 256, 32]          -            -\n",
      "12_pool                    -    [1, 48, 128, 16]          -            -\n",
      "13_dropout                 -    [1, 48, 128, 16]          -            -\n",
      "14_conv_l4    [48, 64, 3, 3]    [1, 64, 128, 16]    27.712k   56.623104M\n",
      "15_bn_l4                [64]    [1, 64, 128, 16]      128.0         64.0\n",
      "16_leakyRelu               -    [1, 64, 128, 16]          -            -\n",
      "17_dropout                 -    [1, 64, 128, 16]          -            -\n",
      "18_conv_l5    [64, 80, 3, 3]    [1, 80, 128, 16]     46.16k    94.37184M\n",
      "19_bn_l5                [80]    [1, 80, 128, 16]      160.0         80.0\n",
      "20_leakyRelu               -    [1, 80, 128, 16]          -            -\n",
      "21_lstm_l1                 -       [1, 128, 512]  9.457664M    9.437184M\n",
      "------------------------------------------------------------------------\n",
      "                           Totals\n",
      "Total params            9.550688M\n",
      "Trainable params        9.550688M\n",
      "Non-trainable params          0.0\n",
      "Mult-Adds             443.547888M\n",
      "========================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_conv_l1</th>\n",
       "      <td>[1, 16, 3, 3]</td>\n",
       "      <td>[1, 16, 1024, 128]</td>\n",
       "      <td>160.0</td>\n",
       "      <td>18874368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_bn_l1</th>\n",
       "      <td>[16]</td>\n",
       "      <td>[1, 16, 1024, 128]</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_leakyRelu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 16, 1024, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_pool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 16, 512, 64]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_conv_l2</th>\n",
       "      <td>[16, 32, 3, 3]</td>\n",
       "      <td>[1, 32, 512, 64]</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>150994944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_bn_l2</th>\n",
       "      <td>[32]</td>\n",
       "      <td>[1, 32, 512, 64]</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_leakyRelu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 512, 64]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_pool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 256, 32]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 32, 256, 32]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_conv_l3</th>\n",
       "      <td>[32, 48, 3, 3]</td>\n",
       "      <td>[1, 48, 256, 32]</td>\n",
       "      <td>13872.0</td>\n",
       "      <td>113246208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_bn_l3</th>\n",
       "      <td>[48]</td>\n",
       "      <td>[1, 48, 256, 32]</td>\n",
       "      <td>96.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_leakyRelu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 48, 256, 32]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_pool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 48, 128, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 48, 128, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_conv_l4</th>\n",
       "      <td>[48, 64, 3, 3]</td>\n",
       "      <td>[1, 64, 128, 16]</td>\n",
       "      <td>27712.0</td>\n",
       "      <td>56623104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_bn_l4</th>\n",
       "      <td>[64]</td>\n",
       "      <td>[1, 64, 128, 16]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_leakyRelu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 64, 128, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_conv_l5</th>\n",
       "      <td>[64, 80, 3, 3]</td>\n",
       "      <td>[1, 80, 128, 16]</td>\n",
       "      <td>46160.0</td>\n",
       "      <td>94371840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19_bn_l5</th>\n",
       "      <td>[80]</td>\n",
       "      <td>[1, 80, 128, 16]</td>\n",
       "      <td>160.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_leakyRelu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 80, 128, 16]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21_lstm_l1</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 128, 512]</td>\n",
       "      <td>9457664.0</td>\n",
       "      <td>9437184.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Kernel Shape        Output Shape     Params    Mult-Adds\n",
       "Layer                                                                   \n",
       "0_conv_l1      [1, 16, 3, 3]  [1, 16, 1024, 128]      160.0   18874368.0\n",
       "1_bn_l1                 [16]  [1, 16, 1024, 128]       32.0         16.0\n",
       "2_leakyRelu                -  [1, 16, 1024, 128]        NaN          NaN\n",
       "3_pool                     -    [1, 16, 512, 64]        NaN          NaN\n",
       "4_conv_l2     [16, 32, 3, 3]    [1, 32, 512, 64]     4640.0  150994944.0\n",
       "5_bn_l2                 [32]    [1, 32, 512, 64]       64.0         32.0\n",
       "6_leakyRelu                -    [1, 32, 512, 64]        NaN          NaN\n",
       "7_pool                     -    [1, 32, 256, 32]        NaN          NaN\n",
       "8_dropout                  -    [1, 32, 256, 32]        NaN          NaN\n",
       "9_conv_l3     [32, 48, 3, 3]    [1, 48, 256, 32]    13872.0  113246208.0\n",
       "10_bn_l3                [48]    [1, 48, 256, 32]       96.0         48.0\n",
       "11_leakyRelu               -    [1, 48, 256, 32]        NaN          NaN\n",
       "12_pool                    -    [1, 48, 128, 16]        NaN          NaN\n",
       "13_dropout                 -    [1, 48, 128, 16]        NaN          NaN\n",
       "14_conv_l4    [48, 64, 3, 3]    [1, 64, 128, 16]    27712.0   56623104.0\n",
       "15_bn_l4                [64]    [1, 64, 128, 16]      128.0         64.0\n",
       "16_leakyRelu               -    [1, 64, 128, 16]        NaN          NaN\n",
       "17_dropout                 -    [1, 64, 128, 16]        NaN          NaN\n",
       "18_conv_l5    [64, 80, 3, 3]    [1, 80, 128, 16]    46160.0   94371840.0\n",
       "19_bn_l5                [80]    [1, 80, 128, 16]      160.0         80.0\n",
       "20_leakyRelu               -    [1, 80, 128, 16]        NaN          NaN\n",
       "21_lstm_l1                 -       [1, 128, 512]  9457664.0    9437184.0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.to(\"cuda\"), torch.zeros(1,1,1024,128).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand(1, 1, 1024, 128).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 1 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1280, 1, 256])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'LitModel' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtualenvs/pytorch-host/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'LitModel' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
