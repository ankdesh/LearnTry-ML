{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" An example showing how to save/restore models and retrieve weights. \"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankdesh/installed/anaconda2/envs/tf0.11/lib/python2.7/gzip.py:275: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  chunk = self.extrabuf[offset: offset + size]\n",
      "/home/ankdesh/installed/anaconda2/envs/tf0.11/lib/python2.7/site-packages/tflearn/datasets/mnist.py:52: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  data = data.reshape(num_images, rows, cols, 1)\n"
     ]
    }
   ],
   "source": [
    "# MNIST Data\n",
    "X, Y, testX, testY = mnist.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.28528\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 001 | loss: 0.28528 - acc: 0.9228 | val_loss: 0.30500 - val_acc: 0.9156 -- iter: 55000/55000\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.28528\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 001 | loss: 0.28528 - acc: 0.9228 | val_loss: 0.30500 - val_acc: 0.9156 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "input_layer = tflearn.input_data(shape=[None, 784], name='input')\n",
    "dense1 = tflearn.fully_connected(input_layer, 128, name='dense1')\n",
    "dense2 = tflearn.fully_connected(dense1, 256, name='dense2')\n",
    "softmax = tflearn.fully_connected(dense2, 10, activation='softmax')\n",
    "regression = tflearn.regression(softmax, optimizer='adam',\n",
    "                                learning_rate=0.001,\n",
    "                                loss='categorical_crossentropy')\n",
    "\n",
    "# Define classifier, with model checkpoint (autosave)\n",
    "model = tflearn.DNN(regression, checkpoint_path='model.tfl.ckpt')\n",
    "\n",
    "# Train model, with model checkpoint every epoch and every 200 training steps.\n",
    "model.fit(X, Y, n_epoch=1,\n",
    "          validation_set=(testX, testY),\n",
    "          show_metric=True,\n",
    "          snapshot_epoch=True, # Snapshot (save & evaluate) model every epoch.\n",
    "          snapshot_step=500, # Snapshot (save & evalaute) model every 500 steps.\n",
    "          run_id='model_and_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense1 layer weights:\n",
      "[[ 0.02016847 -0.0120432  -0.00146774 ..., -0.01501851 -0.00607988\n",
      "  -0.0128871 ]\n",
      " [ 0.00848555  0.00670409 -0.00505784 ..., -0.01526591 -0.00701048\n",
      "  -0.00565379]\n",
      " [-0.00534527 -0.0087175  -0.01811047 ..., -0.00551683  0.03437988\n",
      "  -0.01978657]\n",
      " ..., \n",
      " [-0.02248678  0.02778613  0.00687615 ..., -0.01517815  0.01511721\n",
      "  -0.01216448]\n",
      " [-0.01166681 -0.03815222  0.0195404  ...,  0.020554   -0.00860342\n",
      "   0.00645357]\n",
      " [-0.00197658 -0.01563451 -0.0167937  ..., -0.00785239  0.02784383\n",
      "  -0.00275727]]\n",
      "Dense1 layer biases:\n",
      "[-0.00483045 -0.02626631 -0.08924185 -0.0346124   0.02417278 -0.01819696\n",
      " -0.04836737 -0.03162532  0.026753    0.01777712  0.0115912  -0.04100706\n",
      "  0.0054957  -0.00875653  0.04345272  0.03819585 -0.01714033 -0.13413471\n",
      "  0.01778085  0.03894889 -0.00782998  0.00480117 -0.07080938 -0.02073469\n",
      "  0.08067903 -0.04100002 -0.02849869  0.01947469  0.08119599  0.02877793\n",
      "  0.09796295  0.04716418 -0.00105663 -0.01588985 -0.02753695  0.02431668\n",
      "  0.04482774 -0.026327   -0.05862176 -0.00853216  0.05683649 -0.05021514\n",
      " -0.06174228 -0.03847242 -0.04312211  0.01055591  0.0951331   0.05615025\n",
      "  0.03688717  0.00870897 -0.02654083  0.04922098 -0.11605342  0.00491473\n",
      "  0.0691497   0.10103042 -0.04432456 -0.0026748   0.06239275  0.02497351\n",
      "  0.07644274  0.03108359  0.01670582 -0.08838911 -0.0093603  -0.02683403\n",
      "  0.00311094 -0.10136699  0.00971384 -0.0284556  -0.06372153  0.02307079\n",
      " -0.11519174 -0.0341793  -0.00808044  0.01298558 -0.10807772 -0.04544965\n",
      "  0.02358676  0.07094218  0.03447367  0.02888631  0.05955724 -0.00725732\n",
      " -0.10031364  0.01435831  0.01446419  0.05048507 -0.01818277 -0.05338184\n",
      " -0.01506735  0.01798242  0.06428827  0.03111403  0.07790005 -0.01582216\n",
      "  0.01500861 -0.09897313 -0.01284867 -0.07042535  0.06728538  0.05696419\n",
      "  0.05472377  0.04946681 -0.11938225 -0.10355356 -0.01375364 -0.02439968\n",
      " -0.04603795  0.04181577  0.04306925 -0.04170338 -0.02283311 -0.0410736\n",
      " -0.02096139 -0.00113764 -0.01595158  0.042664    0.00993818  0.06072198\n",
      " -0.04376676 -0.05397907 -0.00862361  0.00158783  0.06401493  0.00466226\n",
      " -0.05195876 -0.08847079]\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# Retrieving weights\n",
    "# ------------------\n",
    "\n",
    "# Retrieve a layer weights, by layer name:\n",
    "dense1_vars = tflearn.variables.get_layer_variables_by_name('dense1')\n",
    "# Get a variable's value, using model `get_weights` method:\n",
    "print(\"Dense1 layer weights:\")\n",
    "print(model.get_weights(dense1_vars[0]))\n",
    "# Or using generic tflearn function:\n",
    "print(\"Dense1 layer biases:\")\n",
    "with model.session.as_default():\n",
    "    print(tflearn.variables.get_value(dense1_vars[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense2 layer weights:\n",
      "[[ 0.01055639  0.08620375  0.04862928 ..., -0.01440148  0.00888839\n",
      "   0.02866616]\n",
      " [ 0.0339524  -0.00818544 -0.00485797 ..., -0.01178635 -0.01184989\n",
      "   0.02456975]\n",
      " [-0.00547604  0.02584333  0.04844898 ...,  0.06854951 -0.00530339\n",
      "   0.05393078]\n",
      " ..., \n",
      " [-0.01961643 -0.07964525 -0.04223059 ..., -0.03262559 -0.03759835\n",
      "  -0.03962386]\n",
      " [-0.0515429  -0.02473955 -0.03541492 ...,  0.00554273  0.01656909\n",
      "  -0.04296798]\n",
      " [ 0.08400296  0.08940421  0.06693238 ...,  0.00980482 -0.00180459\n",
      "   0.03236808]]\n",
      "Dense2 layer biases:\n",
      "[ 0.00044376 -0.04596734 -0.02944141  0.01140089 -0.08871038  0.00932581\n",
      "  0.07159516  0.01199317 -0.00751944 -0.01700861  0.02900777 -0.02915867\n",
      "  0.03783266  0.01565566 -0.03015781  0.01471736  0.00040163  0.06029579\n",
      "  0.04535449 -0.01199872  0.04518174  0.05232766  0.01893858 -0.01036596\n",
      "  0.0747833  -0.01804553 -0.00250435 -0.03463389  0.05454005  0.08295877\n",
      " -0.08360121  0.08016646 -0.01946675  0.09564856 -0.00541074 -0.00456367\n",
      " -0.06820051 -0.0227981  -0.04806037 -0.07027934  0.05791884 -0.07967512\n",
      "  0.0292872   0.030958   -0.02234597 -0.03289153 -0.04065784 -0.03011028\n",
      " -0.04631929  0.08025135 -0.02095441  0.05004947 -0.1117142   0.02335432\n",
      " -0.09719054  0.00082665 -0.08686547 -0.0791176  -0.00022719  0.03343515\n",
      "  0.04631887 -0.03000627  0.07563134 -0.01938253  0.00531547  0.04000702\n",
      "  0.02884917 -0.11164057  0.07022576  0.08999842 -0.0210119  -0.01809722\n",
      " -0.03296576  0.01825298 -0.0396876  -0.00131007  0.06426802  0.00086102\n",
      " -0.0522807  -0.09294562  0.01577203 -0.06093863  0.12040773 -0.06793814\n",
      "  0.07470876 -0.01293117 -0.1142284  -0.00722725  0.03104715  0.01447875\n",
      "  0.02444624  0.00624005 -0.00594125 -0.01051766  0.05600579  0.08343628\n",
      " -0.01012574  0.03907242 -0.02315225 -0.10593527  0.08638621  0.10102545\n",
      "  0.05964974  0.07642809  0.06195705  0.03938029 -0.07255287  0.06490764\n",
      " -0.01957012  0.06659796  0.07818686  0.07546122 -0.01442762 -0.06227902\n",
      " -0.04649244  0.06665886 -0.09676121  0.08326973 -0.0066591   0.04790785\n",
      "  0.04851039 -0.00241074  0.0215018  -0.01202973  0.04631303 -0.0260549\n",
      " -0.02589616  0.02639578 -0.07399424 -0.04090511  0.06300215  0.06260946\n",
      " -0.00888815  0.05031184 -0.05878014  0.04555853  0.00847861 -0.0418972\n",
      "  0.05287578 -0.07092972  0.02184211 -0.01369343 -0.01272309  0.0357103\n",
      " -0.08696438  0.02288235 -0.02464373  0.0775172  -0.05065255 -0.01668891\n",
      "  0.0030528   0.07681397 -0.01196517 -0.01649139  0.0018346  -0.06167923\n",
      "  0.06244427 -0.06979544 -0.02875959 -0.0266421  -0.04479168 -0.05723777\n",
      "  0.04799944 -0.05100569  0.02058857 -0.02090422  0.01909691 -0.00315603\n",
      "  0.0936373   0.0477897  -0.03924963  0.01133077  0.03090353  0.00150087\n",
      "  0.08352139 -0.08515067  0.10378229  0.09885873  0.05915935 -0.08964344\n",
      " -0.03642796  0.01936975 -0.00382609  0.01426715  0.06490277 -0.04093829\n",
      " -0.0269238   0.05307038  0.04154956 -0.03882354  0.02559775 -0.01834336\n",
      "  0.04380363  0.08210652 -0.07555248  0.13321631  0.02514817 -0.06064478\n",
      "  0.07576947  0.02151132  0.05684531  0.02018652  0.00219558 -0.07639214\n",
      "  0.02665022 -0.02329988 -0.0247837   0.00407326  0.00318246 -0.08850891\n",
      "  0.03505753 -0.05485695  0.05310023 -0.0312334  -0.04878676 -0.02629061\n",
      "  0.01817725 -0.02413528  0.09589112  0.01230851  0.05853927  0.10979345\n",
      " -0.09248275  0.00489323 -0.02714806  0.05707289  0.03413362 -0.02355637\n",
      " -0.09755076 -0.02602596 -0.03781185 -0.01779781 -0.00947188  0.04830655\n",
      " -0.03093708  0.02533508  0.0040539   0.069892   -0.11330641 -0.07099034\n",
      "  0.07198028 -0.02283302  0.04921225  0.01060077  0.04112795  0.09809487\n",
      " -0.001895    0.01772279 -0.0040476   0.1020264   0.01064611  0.0807806\n",
      "  0.06040375 -0.11091647  0.07082741  0.0132997 ]\n"
     ]
    }
   ],
   "source": [
    "# It is also possible to retrieve a layer weights through its attributes `W`\n",
    "# and `b` (if available).\n",
    "# Get variable's value, using model `get_weights` method:\n",
    "print(\"Dense2 layer weights:\")\n",
    "print(model.get_weights(dense2.W))\n",
    "# Or using generic tflearn function:\n",
    "print(\"Dense2 layer biases:\")\n",
    "with model.session.as_default():\n",
    "    print(tflearn.variables.get_value(dense2.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
