{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation=nn.Tanh, output_activation=nn.Identity):\n",
    "    # Build a feedforward neural network.\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name='CartPole-v0'\n",
    "hidden_sizes=[32]\n",
    "lr=1e-2\n",
    "epochs=500\n",
    "batch_size=5000\n",
    "render=False\n",
    "\n",
    "# make environment, check spaces, get obs / act dims\n",
    "env = gym.make(env_name)\n",
    "assert isinstance(env.observation_space, Box), \\\n",
    "    \"This example only works for envs with continuous state spaces.\"\n",
    "assert isinstance(env.action_space, Discrete), \\\n",
    "    \"This example only works for envs with discrete action spaces.\"\n",
    "\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "n_acts = env.action_space.n\n",
    "\n",
    "# make core of policy network\n",
    "logits_net = mlp(sizes=[obs_dim]+hidden_sizes+[n_acts])\n",
    "\n",
    "# make function to compute action distribution\n",
    "def get_policy(obs):\n",
    "    logits = logits_net(obs)\n",
    "    return Categorical(logits=logits)\n",
    "\n",
    "# make action selection function (outputs int actions, sampled from policy)\n",
    "def get_action(obs):\n",
    "    return get_policy(obs).sample().item()\n",
    "\n",
    "# make loss function whose gradient, for the right data, is policy gradient\n",
    "def compute_loss(obs, act, weights):\n",
    "    logp = get_policy(obs).log_prob(act)\n",
    "    return -(logp * weights).mean()\n",
    "\n",
    "# make optimizer\n",
    "optimizer = Adam(logits_net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training policy\n",
    "def train_one_epoch():\n",
    "    # make some empty lists for logging.\n",
    "    batch_obs = []          # for observations\n",
    "    batch_acts = []         # for actions\n",
    "    batch_weights = []      # for R(tau) weighting in policy gradient\n",
    "    batch_rets = []         # for measuring episode returns\n",
    "    batch_lens = []         # for measuring episode lengths\n",
    "\n",
    "    # reset episode-specific variables\n",
    "    obs = env.reset()       # first obs comes from starting distribution\n",
    "    done = False            # signal from environment that episode is over\n",
    "    ep_rews = []            # list for rewards accrued throughout ep\n",
    "\n",
    "    # render first episode of each epoch\n",
    "    finished_rendering_this_epoch = False\n",
    "\n",
    "    # collect experience by acting in the environment with current policy\n",
    "    while True:\n",
    "\n",
    "        # rendering\n",
    "        if (not finished_rendering_this_epoch) and render:\n",
    "            env.render()\n",
    "\n",
    "        # save obs\n",
    "        batch_obs.append(obs.copy())\n",
    "\n",
    "        # act in the environment\n",
    "        act = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
    "        obs, rew, done, _ = env.step(act)\n",
    "\n",
    "        # save action, reward\n",
    "        batch_acts.append(act)\n",
    "        ep_rews.append(rew)\n",
    "        \n",
    "        if done:\n",
    "            \n",
    "            #max_x = max(list(zip(*batch_obs))[0])\n",
    "            #print (batch_obs[0], len(batch_obs))\n",
    "            #print (max_x)\n",
    "            # if episode is over, record info about episode\n",
    "            ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "            \n",
    "            #if max_x > -0.2:\n",
    "            #    ep_ret = 1\n",
    "            \n",
    "            batch_rets.append(ep_ret)\n",
    "            batch_lens.append(ep_len)\n",
    "\n",
    "            # the weight for each logprob(a|s) is R(tau)\n",
    "            batch_weights += [ep_ret] * ep_len\n",
    "            #batch_weights += \n",
    "            \n",
    "            # reset episode-specific variables\n",
    "            obs, done, ep_rews = env.reset(), False, []\n",
    "\n",
    "            # won't render again this epoch\n",
    "            finished_rendering_this_epoch = True\n",
    "\n",
    "            # end experience loop if we have enough of it\n",
    "            if len(batch_obs) > batch_size:\n",
    "                break\n",
    "\n",
    "    #print (len(batch_obs) , len(batch_acts))\n",
    "    #print (batch_obs[0], batch_acts[0])\n",
    "    # take a single policy gradient update step\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                              act=torch.as_tensor(batch_acts, dtype=torch.int32),\n",
    "                              weights=torch.as_tensor(batch_weights, dtype=torch.float32)\n",
    "                              )\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    return batch_loss, batch_rets, batch_lens, batch_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss, batch_rets, batch_lens, batch_obs = train_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 \t loss: 17.527 \t return: 20.008 \t ep_len: 20.008\n",
      "epoch:   1 \t loss: 19.639 \t return: 22.326 \t ep_len: 22.326\n",
      "epoch:   2 \t loss: 21.569 \t return: 24.757 \t ep_len: 24.757\n",
      "epoch:   3 \t loss: 24.799 \t return: 29.512 \t ep_len: 29.512\n",
      "epoch:   4 \t loss: 28.229 \t return: 33.480 \t ep_len: 33.480\n",
      "epoch:   5 \t loss: 30.426 \t return: 36.667 \t ep_len: 36.667\n",
      "epoch:   6 \t loss: 35.599 \t return: 42.613 \t ep_len: 42.613\n",
      "epoch:   7 \t loss: 30.436 \t return: 38.114 \t ep_len: 38.114\n",
      "epoch:   8 \t loss: 34.329 \t return: 44.009 \t ep_len: 44.009\n",
      "epoch:   9 \t loss: 44.061 \t return: 52.811 \t ep_len: 52.811\n",
      "epoch:  10 \t loss: 42.245 \t return: 55.022 \t ep_len: 55.022\n",
      "epoch:  11 \t loss: 44.553 \t return: 56.920 \t ep_len: 56.920\n",
      "epoch:  12 \t loss: 42.712 \t return: 59.318 \t ep_len: 59.318\n",
      "epoch:  13 \t loss: 49.204 \t return: 67.573 \t ep_len: 67.573\n",
      "epoch:  14 \t loss: 44.268 \t return: 64.205 \t ep_len: 64.205\n",
      "epoch:  15 \t loss: 46.768 \t return: 67.770 \t ep_len: 67.770\n",
      "epoch:  16 \t loss: 48.568 \t return: 70.803 \t ep_len: 70.803\n",
      "epoch:  17 \t loss: 52.251 \t return: 72.870 \t ep_len: 72.870\n",
      "epoch:  18 \t loss: 52.440 \t return: 77.431 \t ep_len: 77.431\n",
      "epoch:  19 \t loss: 51.560 \t return: 80.438 \t ep_len: 80.438\n",
      "epoch:  20 \t loss: 64.900 \t return: 97.404 \t ep_len: 97.404\n",
      "epoch:  21 \t loss: 67.364 \t return: 104.271 \t ep_len: 104.271\n",
      "epoch:  22 \t loss: 71.332 \t return: 111.326 \t ep_len: 111.326\n",
      "epoch:  23 \t loss: 68.397 \t return: 109.043 \t ep_len: 109.043\n",
      "epoch:  24 \t loss: 74.246 \t return: 122.714 \t ep_len: 122.714\n",
      "epoch:  25 \t loss: 82.177 \t return: 136.189 \t ep_len: 136.189\n",
      "epoch:  26 \t loss: 89.432 \t return: 154.182 \t ep_len: 154.182\n",
      "epoch:  27 \t loss: 86.447 \t return: 148.206 \t ep_len: 148.206\n",
      "epoch:  28 \t loss: 83.983 \t return: 140.861 \t ep_len: 140.861\n",
      "epoch:  29 \t loss: 85.007 \t return: 153.424 \t ep_len: 153.424\n",
      "epoch:  30 \t loss: 89.215 \t return: 158.688 \t ep_len: 158.688\n",
      "epoch:  31 \t loss: 89.346 \t return: 159.125 \t ep_len: 159.125\n",
      "epoch:  32 \t loss: 92.453 \t return: 167.533 \t ep_len: 167.533\n",
      "epoch:  33 \t loss: 99.937 \t return: 185.593 \t ep_len: 185.593\n",
      "epoch:  34 \t loss: 95.129 \t return: 175.000 \t ep_len: 175.000\n",
      "epoch:  35 \t loss: 97.096 \t return: 178.821 \t ep_len: 178.821\n",
      "epoch:  36 \t loss: 95.852 \t return: 174.034 \t ep_len: 174.034\n",
      "epoch:  37 \t loss: 90.941 \t return: 167.233 \t ep_len: 167.233\n",
      "epoch:  38 \t loss: 88.510 \t return: 164.161 \t ep_len: 164.161\n",
      "epoch:  39 \t loss: 83.760 \t return: 152.176 \t ep_len: 152.176\n",
      "epoch:  40 \t loss: 86.357 \t return: 157.406 \t ep_len: 157.406\n",
      "epoch:  41 \t loss: 86.843 \t return: 160.031 \t ep_len: 160.031\n",
      "epoch:  42 \t loss: 84.242 \t return: 159.156 \t ep_len: 159.156\n",
      "epoch:  43 \t loss: 89.180 \t return: 167.233 \t ep_len: 167.233\n",
      "epoch:  44 \t loss: 89.570 \t return: 167.467 \t ep_len: 167.467\n",
      "epoch:  45 \t loss: 93.763 \t return: 180.250 \t ep_len: 180.250\n",
      "epoch:  46 \t loss: 96.775 \t return: 190.111 \t ep_len: 190.111\n",
      "epoch:  47 \t loss: 99.621 \t return: 190.630 \t ep_len: 190.630\n",
      "epoch:  48 \t loss: 99.444 \t return: 191.074 \t ep_len: 191.074\n",
      "epoch:  49 \t loss: 96.507 \t return: 189.481 \t ep_len: 189.481\n",
      "epoch:  50 \t loss: 93.604 \t return: 176.310 \t ep_len: 176.310\n",
      "epoch:  51 \t loss: 92.149 \t return: 176.138 \t ep_len: 176.138\n",
      "epoch:  52 \t loss: 83.063 \t return: 155.545 \t ep_len: 155.545\n",
      "epoch:  53 \t loss: 83.717 \t return: 157.312 \t ep_len: 157.312\n",
      "epoch:  54 \t loss: 81.814 \t return: 154.182 \t ep_len: 154.182\n",
      "epoch:  55 \t loss: 80.068 \t return: 152.242 \t ep_len: 152.242\n",
      "epoch:  56 \t loss: 84.270 \t return: 158.719 \t ep_len: 158.719\n",
      "epoch:  57 \t loss: 84.332 \t return: 158.000 \t ep_len: 158.000\n",
      "epoch:  58 \t loss: 90.016 \t return: 170.333 \t ep_len: 170.333\n",
      "epoch:  59 \t loss: 94.192 \t return: 180.357 \t ep_len: 180.357\n",
      "epoch:  60 \t loss: 93.714 \t return: 178.448 \t ep_len: 178.448\n",
      "epoch:  61 \t loss: 97.374 \t return: 185.407 \t ep_len: 185.407\n",
      "epoch:  62 \t loss: 98.115 \t return: 190.370 \t ep_len: 190.370\n",
      "epoch:  63 \t loss: 100.139 \t return: 194.654 \t ep_len: 194.654\n",
      "epoch:  64 \t loss: 99.979 \t return: 194.692 \t ep_len: 194.692\n",
      "epoch:  65 \t loss: 101.767 \t return: 197.808 \t ep_len: 197.808\n",
      "epoch:  66 \t loss: 101.893 \t return: 197.885 \t ep_len: 197.885\n",
      "epoch:  67 \t loss: 102.501 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  68 \t loss: 101.032 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  69 \t loss: 101.676 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  70 \t loss: 103.086 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  71 \t loss: 101.576 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  72 \t loss: 103.446 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  73 \t loss: 101.598 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  74 \t loss: 101.539 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  75 \t loss: 101.675 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  76 \t loss: 103.642 \t return: 199.808 \t ep_len: 199.808\n",
      "epoch:  77 \t loss: 103.649 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  78 \t loss: 101.302 \t return: 199.615 \t ep_len: 199.615\n",
      "epoch:  79 \t loss: 102.430 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  80 \t loss: 101.313 \t return: 195.885 \t ep_len: 195.885\n",
      "epoch:  81 \t loss: 101.890 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  82 \t loss: 100.908 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  83 \t loss: 99.362 \t return: 196.962 \t ep_len: 196.962\n",
      "epoch:  84 \t loss: 98.767 \t return: 193.500 \t ep_len: 193.500\n",
      "epoch:  85 \t loss: 101.826 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  86 \t loss: 98.389 \t return: 196.115 \t ep_len: 196.115\n",
      "epoch:  87 \t loss: 100.996 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  88 \t loss: 98.009 \t return: 193.692 \t ep_len: 193.692\n",
      "epoch:  89 \t loss: 99.297 \t return: 199.923 \t ep_len: 199.923\n",
      "epoch:  90 \t loss: 98.601 \t return: 188.630 \t ep_len: 188.630\n",
      "epoch:  91 \t loss: 99.203 \t return: 199.385 \t ep_len: 199.385\n",
      "epoch:  92 \t loss: 98.141 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  93 \t loss: 97.793 \t return: 196.846 \t ep_len: 196.846\n",
      "epoch:  94 \t loss: 97.449 \t return: 197.423 \t ep_len: 197.423\n",
      "epoch:  95 \t loss: 98.601 \t return: 197.115 \t ep_len: 197.115\n",
      "epoch:  96 \t loss: 98.400 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch:  97 \t loss: 93.697 \t return: 186.815 \t ep_len: 186.815\n",
      "epoch:  98 \t loss: 78.638 \t return: 152.618 \t ep_len: 152.618\n",
      "epoch:  99 \t loss: 76.508 \t return: 152.667 \t ep_len: 152.667\n",
      "epoch: 100 \t loss: 68.334 \t return: 133.947 \t ep_len: 133.947\n",
      "epoch: 101 \t loss: 61.864 \t return: 123.244 \t ep_len: 123.244\n",
      "epoch: 102 \t loss: 58.451 \t return: 119.405 \t ep_len: 119.405\n",
      "epoch: 103 \t loss: 58.132 \t return: 115.773 \t ep_len: 115.773\n",
      "epoch: 104 \t loss: 55.708 \t return: 112.867 \t ep_len: 112.867\n",
      "epoch: 105 \t loss: 59.703 \t return: 116.628 \t ep_len: 116.628\n",
      "epoch: 106 \t loss: 56.276 \t return: 115.136 \t ep_len: 115.136\n",
      "epoch: 107 \t loss: 56.158 \t return: 112.400 \t ep_len: 112.400\n",
      "epoch: 108 \t loss: 59.770 \t return: 121.452 \t ep_len: 121.452\n",
      "epoch: 109 \t loss: 60.914 \t return: 121.619 \t ep_len: 121.619\n",
      "epoch: 110 \t loss: 62.618 \t return: 126.325 \t ep_len: 126.325\n",
      "epoch: 111 \t loss: 64.163 \t return: 131.684 \t ep_len: 131.684\n",
      "epoch: 112 \t loss: 67.371 \t return: 136.784 \t ep_len: 136.784\n",
      "epoch: 113 \t loss: 67.855 \t return: 138.676 \t ep_len: 138.676\n",
      "epoch: 114 \t loss: 70.253 \t return: 140.472 \t ep_len: 140.472\n",
      "epoch: 115 \t loss: 71.563 \t return: 145.829 \t ep_len: 145.829\n",
      "epoch: 116 \t loss: 73.755 \t return: 151.697 \t ep_len: 151.697\n",
      "epoch: 117 \t loss: 74.153 \t return: 152.636 \t ep_len: 152.636\n",
      "epoch: 118 \t loss: 75.337 \t return: 155.364 \t ep_len: 155.364\n",
      "epoch: 119 \t loss: 77.788 \t return: 158.781 \t ep_len: 158.781\n",
      "epoch: 120 \t loss: 83.447 \t return: 168.567 \t ep_len: 168.567\n",
      "epoch: 121 \t loss: 83.516 \t return: 172.667 \t ep_len: 172.667\n",
      "epoch: 122 \t loss: 85.867 \t return: 175.207 \t ep_len: 175.207\n",
      "epoch: 123 \t loss: 90.458 \t return: 188.407 \t ep_len: 188.407\n",
      "epoch: 124 \t loss: 94.513 \t return: 196.538 \t ep_len: 196.538\n",
      "epoch: 125 \t loss: 96.163 \t return: 198.885 \t ep_len: 198.885\n",
      "epoch: 126 \t loss: 95.100 \t return: 199.808 \t ep_len: 199.808\n",
      "epoch: 127 \t loss: 96.245 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 128 \t loss: 96.462 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 129 \t loss: 96.908 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 130 \t loss: 95.184 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 131 \t loss: 97.393 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 132 \t loss: 95.910 \t return: 200.000 \t ep_len: 200.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133 \t loss: 95.401 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 134 \t loss: 97.923 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 135 \t loss: 96.441 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 136 \t loss: 95.791 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 137 \t loss: 97.099 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 138 \t loss: 96.288 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 139 \t loss: 98.436 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 140 \t loss: 96.416 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 141 \t loss: 96.994 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 142 \t loss: 98.508 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 143 \t loss: 97.955 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 144 \t loss: 97.948 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 145 \t loss: 98.229 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 146 \t loss: 99.813 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 147 \t loss: 98.970 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 148 \t loss: 101.252 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 149 \t loss: 101.627 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 150 \t loss: 103.654 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 151 \t loss: 103.194 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 152 \t loss: 103.273 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 153 \t loss: 105.142 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 154 \t loss: 103.238 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 155 \t loss: 103.915 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 156 \t loss: 105.243 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 157 \t loss: 103.993 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 158 \t loss: 104.718 \t return: 198.654 \t ep_len: 198.654\n",
      "epoch: 159 \t loss: 107.235 \t return: 199.846 \t ep_len: 199.846\n",
      "epoch: 160 \t loss: 105.467 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 161 \t loss: 106.633 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 162 \t loss: 106.060 \t return: 198.385 \t ep_len: 198.385\n",
      "epoch: 163 \t loss: 106.736 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 164 \t loss: 106.098 \t return: 199.423 \t ep_len: 199.423\n",
      "epoch: 165 \t loss: 106.893 \t return: 196.654 \t ep_len: 196.654\n",
      "epoch: 166 \t loss: 107.078 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 167 \t loss: 107.767 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 168 \t loss: 107.687 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 169 \t loss: 106.834 \t return: 196.577 \t ep_len: 196.577\n",
      "epoch: 170 \t loss: 106.842 \t return: 196.308 \t ep_len: 196.308\n",
      "epoch: 171 \t loss: 106.437 \t return: 196.962 \t ep_len: 196.962\n",
      "epoch: 172 \t loss: 107.985 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 173 \t loss: 105.802 \t return: 194.385 \t ep_len: 194.385\n",
      "epoch: 174 \t loss: 106.353 \t return: 198.808 \t ep_len: 198.808\n",
      "epoch: 175 \t loss: 105.496 \t return: 197.615 \t ep_len: 197.615\n",
      "epoch: 176 \t loss: 104.353 \t return: 196.769 \t ep_len: 196.769\n",
      "epoch: 177 \t loss: 105.294 \t return: 198.115 \t ep_len: 198.115\n",
      "epoch: 178 \t loss: 103.397 \t return: 196.769 \t ep_len: 196.769\n",
      "epoch: 179 \t loss: 102.611 \t return: 193.769 \t ep_len: 193.769\n",
      "epoch: 180 \t loss: 103.502 \t return: 197.000 \t ep_len: 197.000\n",
      "epoch: 181 \t loss: 104.693 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 182 \t loss: 105.115 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 183 \t loss: 103.740 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 184 \t loss: 105.593 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 185 \t loss: 104.944 \t return: 199.885 \t ep_len: 199.885\n",
      "epoch: 186 \t loss: 103.979 \t return: 198.885 \t ep_len: 198.885\n",
      "epoch: 187 \t loss: 103.000 \t return: 192.074 \t ep_len: 192.074\n",
      "epoch: 188 \t loss: 103.445 \t return: 195.538 \t ep_len: 195.538\n",
      "epoch: 189 \t loss: 103.430 \t return: 189.185 \t ep_len: 189.185\n",
      "epoch: 190 \t loss: 105.139 \t return: 195.423 \t ep_len: 195.423\n",
      "epoch: 191 \t loss: 106.008 \t return: 195.923 \t ep_len: 195.923\n",
      "epoch: 192 \t loss: 104.592 \t return: 192.885 \t ep_len: 192.885\n",
      "epoch: 193 \t loss: 104.257 \t return: 192.923 \t ep_len: 192.923\n",
      "epoch: 194 \t loss: 106.521 \t return: 198.769 \t ep_len: 198.769\n",
      "epoch: 195 \t loss: 107.162 \t return: 196.231 \t ep_len: 196.231\n",
      "epoch: 196 \t loss: 105.841 \t return: 195.846 \t ep_len: 195.846\n",
      "epoch: 197 \t loss: 106.288 \t return: 194.885 \t ep_len: 194.885\n",
      "epoch: 198 \t loss: 104.402 \t return: 187.778 \t ep_len: 187.778\n",
      "epoch: 199 \t loss: 108.197 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 200 \t loss: 105.659 \t return: 195.423 \t ep_len: 195.423\n",
      "epoch: 201 \t loss: 107.061 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 202 \t loss: 105.483 \t return: 196.231 \t ep_len: 196.231\n",
      "epoch: 203 \t loss: 106.971 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 204 \t loss: 104.958 \t return: 194.423 \t ep_len: 194.423\n",
      "epoch: 205 \t loss: 104.921 \t return: 194.692 \t ep_len: 194.692\n",
      "epoch: 206 \t loss: 105.235 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 207 \t loss: 104.747 \t return: 198.654 \t ep_len: 198.654\n",
      "epoch: 208 \t loss: 104.866 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 209 \t loss: 105.901 \t return: 199.577 \t ep_len: 199.577\n",
      "epoch: 210 \t loss: 104.263 \t return: 199.038 \t ep_len: 199.038\n",
      "epoch: 211 \t loss: 103.233 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 212 \t loss: 103.601 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 213 \t loss: 103.264 \t return: 195.038 \t ep_len: 195.038\n",
      "epoch: 214 \t loss: 105.037 \t return: 199.231 \t ep_len: 199.231\n",
      "epoch: 215 \t loss: 104.893 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 216 \t loss: 103.725 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 217 \t loss: 103.315 \t return: 196.423 \t ep_len: 196.423\n",
      "epoch: 218 \t loss: 106.260 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 219 \t loss: 106.281 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 220 \t loss: 104.608 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 221 \t loss: 105.513 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 222 \t loss: 106.174 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 223 \t loss: 106.250 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 224 \t loss: 105.574 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 225 \t loss: 106.194 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 226 \t loss: 105.912 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 227 \t loss: 105.617 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 228 \t loss: 103.141 \t return: 198.115 \t ep_len: 198.115\n",
      "epoch: 229 \t loss: 105.338 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 230 \t loss: 104.742 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 231 \t loss: 104.647 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 232 \t loss: 102.491 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 233 \t loss: 103.206 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 234 \t loss: 102.515 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 235 \t loss: 103.698 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 236 \t loss: 102.966 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 237 \t loss: 103.403 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 238 \t loss: 103.440 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 239 \t loss: 103.129 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 240 \t loss: 103.183 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 241 \t loss: 101.588 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 242 \t loss: 101.764 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 243 \t loss: 103.153 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 244 \t loss: 103.320 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 245 \t loss: 102.352 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 246 \t loss: 100.719 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 247 \t loss: 99.267 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 248 \t loss: 98.908 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 249 \t loss: 99.602 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 250 \t loss: 99.598 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 251 \t loss: 97.905 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 252 \t loss: 96.158 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 253 \t loss: 98.382 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 254 \t loss: 95.609 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 255 \t loss: 95.435 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 256 \t loss: 92.983 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 257 \t loss: 94.192 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 258 \t loss: 92.513 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 259 \t loss: 93.852 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 260 \t loss: 92.267 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 261 \t loss: 91.884 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 262 \t loss: 90.625 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 263 \t loss: 91.370 \t return: 200.000 \t ep_len: 200.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 264 \t loss: 90.768 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 265 \t loss: 90.539 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 266 \t loss: 90.336 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 267 \t loss: 89.556 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 268 \t loss: 90.468 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 269 \t loss: 89.792 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 270 \t loss: 88.002 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 271 \t loss: 87.937 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 272 \t loss: 88.799 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 273 \t loss: 88.190 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 274 \t loss: 88.062 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 275 \t loss: 88.551 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 276 \t loss: 86.425 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 277 \t loss: 89.508 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 278 \t loss: 86.008 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 279 \t loss: 88.257 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 280 \t loss: 89.036 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 281 \t loss: 88.506 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 282 \t loss: 88.023 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 283 \t loss: 87.247 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 284 \t loss: 85.568 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 285 \t loss: 88.734 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 286 \t loss: 87.034 \t return: 197.962 \t ep_len: 197.962\n",
      "epoch: 287 \t loss: 85.662 \t return: 193.654 \t ep_len: 193.654\n",
      "epoch: 288 \t loss: 81.493 \t return: 185.593 \t ep_len: 185.593\n",
      "epoch: 289 \t loss: 81.157 \t return: 184.857 \t ep_len: 184.857\n",
      "epoch: 290 \t loss: 80.450 \t return: 177.103 \t ep_len: 177.103\n",
      "epoch: 291 \t loss: 75.966 \t return: 173.000 \t ep_len: 173.000\n",
      "epoch: 292 \t loss: 76.180 \t return: 175.517 \t ep_len: 175.517\n",
      "epoch: 293 \t loss: 77.918 \t return: 175.517 \t ep_len: 175.517\n",
      "epoch: 294 \t loss: 77.993 \t return: 175.793 \t ep_len: 175.793\n",
      "epoch: 295 \t loss: 73.623 \t return: 170.400 \t ep_len: 170.400\n",
      "epoch: 296 \t loss: 73.598 \t return: 164.645 \t ep_len: 164.645\n",
      "epoch: 297 \t loss: 70.768 \t return: 161.323 \t ep_len: 161.323\n",
      "epoch: 298 \t loss: 69.597 \t return: 162.613 \t ep_len: 162.613\n",
      "epoch: 299 \t loss: 69.394 \t return: 162.065 \t ep_len: 162.065\n",
      "epoch: 300 \t loss: 71.297 \t return: 165.935 \t ep_len: 165.935\n",
      "epoch: 301 \t loss: 70.672 \t return: 163.935 \t ep_len: 163.935\n",
      "epoch: 302 \t loss: 69.635 \t return: 160.406 \t ep_len: 160.406\n",
      "epoch: 303 \t loss: 66.213 \t return: 156.781 \t ep_len: 156.781\n",
      "epoch: 304 \t loss: 64.769 \t return: 151.697 \t ep_len: 151.697\n",
      "epoch: 305 \t loss: 62.621 \t return: 146.486 \t ep_len: 146.486\n",
      "epoch: 306 \t loss: 58.048 \t return: 139.972 \t ep_len: 139.972\n",
      "epoch: 307 \t loss: 59.069 \t return: 138.973 \t ep_len: 138.973\n",
      "epoch: 308 \t loss: 55.906 \t return: 135.541 \t ep_len: 135.541\n",
      "epoch: 309 \t loss: 54.083 \t return: 130.564 \t ep_len: 130.564\n",
      "epoch: 310 \t loss: 54.297 \t return: 128.769 \t ep_len: 128.769\n",
      "epoch: 311 \t loss: 52.517 \t return: 128.667 \t ep_len: 128.667\n",
      "epoch: 312 \t loss: 53.166 \t return: 131.154 \t ep_len: 131.154\n",
      "epoch: 313 \t loss: 52.987 \t return: 130.564 \t ep_len: 130.564\n",
      "epoch: 314 \t loss: 53.290 \t return: 129.487 \t ep_len: 129.487\n",
      "epoch: 315 \t loss: 50.614 \t return: 125.675 \t ep_len: 125.675\n",
      "epoch: 316 \t loss: 51.609 \t return: 127.150 \t ep_len: 127.150\n",
      "epoch: 317 \t loss: 50.182 \t return: 126.125 \t ep_len: 126.125\n",
      "epoch: 318 \t loss: 50.383 \t return: 125.475 \t ep_len: 125.475\n",
      "epoch: 319 \t loss: 51.047 \t return: 125.366 \t ep_len: 125.366\n",
      "epoch: 320 \t loss: 50.903 \t return: 125.200 \t ep_len: 125.200\n",
      "epoch: 321 \t loss: 51.494 \t return: 126.150 \t ep_len: 126.150\n",
      "epoch: 322 \t loss: 49.833 \t return: 126.025 \t ep_len: 126.025\n",
      "epoch: 323 \t loss: 51.519 \t return: 127.500 \t ep_len: 127.500\n",
      "epoch: 324 \t loss: 51.817 \t return: 129.128 \t ep_len: 129.128\n",
      "epoch: 325 \t loss: 54.113 \t return: 132.605 \t ep_len: 132.605\n",
      "epoch: 326 \t loss: 53.292 \t return: 131.684 \t ep_len: 131.684\n",
      "epoch: 327 \t loss: 55.740 \t return: 140.944 \t ep_len: 140.944\n",
      "epoch: 328 \t loss: 58.183 \t return: 143.361 \t ep_len: 143.361\n",
      "epoch: 329 \t loss: 61.654 \t return: 151.879 \t ep_len: 151.879\n",
      "epoch: 330 \t loss: 66.952 \t return: 167.967 \t ep_len: 167.967\n",
      "epoch: 331 \t loss: 71.698 \t return: 174.517 \t ep_len: 174.517\n",
      "epoch: 332 \t loss: 77.770 \t return: 191.444 \t ep_len: 191.444\n",
      "epoch: 333 \t loss: 81.478 \t return: 198.308 \t ep_len: 198.308\n",
      "epoch: 334 \t loss: 81.574 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 335 \t loss: 81.964 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 336 \t loss: 81.983 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 337 \t loss: 82.733 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 338 \t loss: 82.696 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 339 \t loss: 81.315 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 340 \t loss: 82.504 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 341 \t loss: 84.076 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 342 \t loss: 82.380 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 343 \t loss: 85.629 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 344 \t loss: 83.443 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 345 \t loss: 83.080 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 346 \t loss: 84.061 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 347 \t loss: 84.920 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 348 \t loss: 83.310 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 349 \t loss: 82.997 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 350 \t loss: 82.878 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 351 \t loss: 83.518 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 352 \t loss: 83.847 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 353 \t loss: 83.822 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 354 \t loss: 83.765 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 355 \t loss: 83.492 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 356 \t loss: 82.005 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 357 \t loss: 83.581 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 358 \t loss: 83.110 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 359 \t loss: 83.736 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 360 \t loss: 83.582 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 361 \t loss: 82.377 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 362 \t loss: 83.765 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 363 \t loss: 82.196 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 364 \t loss: 82.894 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 365 \t loss: 82.085 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 366 \t loss: 83.193 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 367 \t loss: 80.590 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 368 \t loss: 81.275 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 369 \t loss: 81.303 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 370 \t loss: 81.274 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 371 \t loss: 79.145 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 372 \t loss: 77.716 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 373 \t loss: 80.320 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 374 \t loss: 78.218 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 375 \t loss: 77.220 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 376 \t loss: 76.019 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 377 \t loss: 77.100 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 378 \t loss: 75.015 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 379 \t loss: 76.669 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 380 \t loss: 75.026 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 381 \t loss: 74.857 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 382 \t loss: 72.544 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 383 \t loss: 73.779 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 384 \t loss: 73.112 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 385 \t loss: 72.458 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 386 \t loss: 72.670 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 387 \t loss: 70.741 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 388 \t loss: 71.748 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 389 \t loss: 70.471 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 390 \t loss: 70.818 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 391 \t loss: 71.257 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 392 \t loss: 69.448 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 393 \t loss: 67.575 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 394 \t loss: 68.829 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 395 \t loss: 67.338 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 396 \t loss: 70.504 \t return: 200.000 \t ep_len: 200.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 397 \t loss: 68.654 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 398 \t loss: 68.755 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 399 \t loss: 68.802 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 400 \t loss: 69.787 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 401 \t loss: 69.084 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 402 \t loss: 71.099 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 403 \t loss: 70.223 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 404 \t loss: 70.069 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 405 \t loss: 70.192 \t return: 199.962 \t ep_len: 199.962\n",
      "epoch: 406 \t loss: 70.917 \t return: 199.000 \t ep_len: 199.000\n",
      "epoch: 407 \t loss: 68.713 \t return: 199.115 \t ep_len: 199.115\n",
      "epoch: 408 \t loss: 68.126 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 409 \t loss: 68.849 \t return: 199.769 \t ep_len: 199.769\n",
      "epoch: 410 \t loss: 69.096 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 411 \t loss: 70.108 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 412 \t loss: 70.508 \t return: 199.962 \t ep_len: 199.962\n",
      "epoch: 413 \t loss: 68.716 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 414 \t loss: 72.444 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 415 \t loss: 69.416 \t return: 199.769 \t ep_len: 199.769\n",
      "epoch: 416 \t loss: 67.737 \t return: 198.615 \t ep_len: 198.615\n",
      "epoch: 417 \t loss: 70.776 \t return: 196.654 \t ep_len: 196.654\n",
      "epoch: 418 \t loss: 67.928 \t return: 196.077 \t ep_len: 196.077\n",
      "epoch: 419 \t loss: 69.834 \t return: 192.556 \t ep_len: 192.556\n",
      "epoch: 420 \t loss: 67.391 \t return: 185.143 \t ep_len: 185.143\n",
      "epoch: 421 \t loss: 63.055 \t return: 173.483 \t ep_len: 173.483\n",
      "epoch: 422 \t loss: 58.489 \t return: 163.484 \t ep_len: 163.484\n",
      "epoch: 423 \t loss: 59.265 \t return: 162.387 \t ep_len: 162.387\n",
      "epoch: 424 \t loss: 60.008 \t return: 167.933 \t ep_len: 167.933\n",
      "epoch: 425 \t loss: 66.218 \t return: 177.966 \t ep_len: 177.966\n",
      "epoch: 426 \t loss: 68.576 \t return: 188.074 \t ep_len: 188.074\n",
      "epoch: 427 \t loss: 70.443 \t return: 193.808 \t ep_len: 193.808\n",
      "epoch: 428 \t loss: 72.700 \t return: 198.346 \t ep_len: 198.346\n",
      "epoch: 429 \t loss: 72.498 \t return: 198.192 \t ep_len: 198.192\n",
      "epoch: 430 \t loss: 70.728 \t return: 196.154 \t ep_len: 196.154\n",
      "epoch: 431 \t loss: 73.682 \t return: 197.846 \t ep_len: 197.846\n",
      "epoch: 432 \t loss: 74.872 \t return: 198.308 \t ep_len: 198.308\n",
      "epoch: 433 \t loss: 72.244 \t return: 197.577 \t ep_len: 197.577\n",
      "epoch: 434 \t loss: 71.871 \t return: 197.846 \t ep_len: 197.846\n",
      "epoch: 435 \t loss: 73.871 \t return: 199.538 \t ep_len: 199.538\n",
      "epoch: 436 \t loss: 74.018 \t return: 199.462 \t ep_len: 199.462\n",
      "epoch: 437 \t loss: 74.147 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 438 \t loss: 73.737 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 439 \t loss: 72.523 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 440 \t loss: 74.614 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 441 \t loss: 74.853 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 442 \t loss: 75.297 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 443 \t loss: 73.433 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 444 \t loss: 73.192 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 445 \t loss: 77.134 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 446 \t loss: 73.772 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 447 \t loss: 72.416 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 448 \t loss: 74.423 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 449 \t loss: 74.038 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 450 \t loss: 74.839 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 451 \t loss: 74.780 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 452 \t loss: 74.620 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 453 \t loss: 73.599 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 454 \t loss: 76.440 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 455 \t loss: 75.519 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 456 \t loss: 75.937 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 457 \t loss: 75.267 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 458 \t loss: 75.041 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 459 \t loss: 75.618 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 460 \t loss: 75.304 \t return: 199.731 \t ep_len: 199.731\n",
      "epoch: 461 \t loss: 78.020 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 462 \t loss: 76.472 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 463 \t loss: 77.940 \t return: 199.615 \t ep_len: 199.615\n",
      "epoch: 464 \t loss: 77.064 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 465 \t loss: 76.607 \t return: 199.962 \t ep_len: 199.962\n",
      "epoch: 466 \t loss: 77.656 \t return: 199.731 \t ep_len: 199.731\n",
      "epoch: 467 \t loss: 77.696 \t return: 199.385 \t ep_len: 199.385\n",
      "epoch: 468 \t loss: 76.626 \t return: 198.846 \t ep_len: 198.846\n",
      "epoch: 469 \t loss: 76.177 \t return: 199.846 \t ep_len: 199.846\n",
      "epoch: 470 \t loss: 78.352 \t return: 199.846 \t ep_len: 199.846\n",
      "epoch: 471 \t loss: 76.455 \t return: 199.808 \t ep_len: 199.808\n",
      "epoch: 472 \t loss: 78.470 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 473 \t loss: 76.369 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 474 \t loss: 78.405 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 475 \t loss: 78.212 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 476 \t loss: 77.910 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 477 \t loss: 77.688 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 478 \t loss: 75.659 \t return: 195.692 \t ep_len: 195.692\n",
      "epoch: 479 \t loss: 78.074 \t return: 200.000 \t ep_len: 200.000\n",
      "epoch: 480 \t loss: 76.556 \t return: 191.852 \t ep_len: 191.852\n",
      "epoch: 481 \t loss: 77.136 \t return: 195.231 \t ep_len: 195.231\n",
      "epoch: 482 \t loss: 76.032 \t return: 191.741 \t ep_len: 191.741\n",
      "epoch: 483 \t loss: 77.876 \t return: 195.692 \t ep_len: 195.692\n",
      "epoch: 484 \t loss: 78.095 \t return: 196.462 \t ep_len: 196.462\n",
      "epoch: 485 \t loss: 77.783 \t return: 191.741 \t ep_len: 191.741\n",
      "epoch: 486 \t loss: 78.190 \t return: 195.500 \t ep_len: 195.500\n",
      "epoch: 487 \t loss: 75.637 \t return: 187.519 \t ep_len: 187.519\n",
      "epoch: 488 \t loss: 76.150 \t return: 181.714 \t ep_len: 181.714\n",
      "epoch: 489 \t loss: 75.616 \t return: 187.963 \t ep_len: 187.963\n",
      "epoch: 490 \t loss: 75.331 \t return: 189.926 \t ep_len: 189.926\n",
      "epoch: 491 \t loss: 72.832 \t return: 187.259 \t ep_len: 187.259\n",
      "epoch: 492 \t loss: 72.488 \t return: 179.000 \t ep_len: 179.000\n",
      "epoch: 493 \t loss: 73.413 \t return: 189.852 \t ep_len: 189.852\n",
      "epoch: 494 \t loss: 72.756 \t return: 188.074 \t ep_len: 188.074\n",
      "epoch: 495 \t loss: 70.163 \t return: 187.000 \t ep_len: 187.000\n",
      "epoch: 496 \t loss: 69.429 \t return: 188.444 \t ep_len: 188.444\n",
      "epoch: 497 \t loss: 71.237 \t return: 194.962 \t ep_len: 194.962\n",
      "epoch: 498 \t loss: 71.543 \t return: 193.846 \t ep_len: 193.846\n",
      "epoch: 499 \t loss: 70.376 \t return: 190.519 \t ep_len: 190.519\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "logs = []\n",
    "for i in range(epochs):\n",
    "    batch_loss, batch_rets, batch_lens,_ = train_one_epoch()\n",
    "    logs.append((batch_loss, batch_rets, batch_lens))\n",
    "    print('epoch: %3d \\t loss: %.3f \\t return: %.3f \\t ep_len: %.3f'%\n",
    "            (i, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(logs), logs[0][0], len(logs[0][1]), len(logs[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = list(zip(*logs))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_returns = [np.mean(x) for x in returns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (mean_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
