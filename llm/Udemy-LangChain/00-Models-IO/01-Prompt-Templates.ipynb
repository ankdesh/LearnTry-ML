{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcded1a6-2430-4707-a78c-c82f4c5ee6fc",
   "metadata": {},
   "source": [
    "<a href = \"https://www.pieriantraining.com\"><img src=\"../PT Centered Purple.png\"> </a>\n",
    "\n",
    "<em style=\"text-align:center\">Copyrighted by Pierian Training</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b99d72-d919-4362-a3e9-14e361f231b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Understanding Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf51224-6f3b-4093-a0e1-338c8eae22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = open(\"/home/ankdesh/explore/openai-key\").readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb72664-ce8d-4d88-b003-8a930ff2c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankdesh/explore/LearnTry-ML/llm/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/ankdesh/explore/LearnTry-ML/llm/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pluto was first discovered in 1930 by astronomer Clyde Tombaugh, but it was not named by its discoverer. The name \"Pluto\" was suggested by an 11-year-old girl named Venetia Burney, who thought the name of the Roman god of the underworld was fitting for the farthest and coldest planet in our solar system. The name was officially adopted by the International Astronomical Union in 1930.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(openai_api_key=api_key)\n",
    "print(llm('Here is a fun fact about Pluto:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579bfe0-103e-430e-bac6-fa9fa50055b5",
   "metadata": {},
   "source": [
    "You can also use generate to get full output with more info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24db968b-ef5a-4a31-bbb9-a08e48cb0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDS TO BE A LIST, EVEN FOR JUST ONE STRING\n",
    "result = llm.generate(['Here is a fun fact about Pluto:',\n",
    "                     'Here is a fun fact about Mars:']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d87f8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLMResult(generations=[[Generation(text='\\n\\nPluto was named by an 11-year-old girl named Venetia Burney in 1930. She suggested the name after the Roman god of the underworld, and it was chosen by the Lowell Observatory in Arizona.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 16, 'completion_tokens': 99, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo-instruct'}, run=None),\n",
      " LLMResult(generations=[[Generation(text='\\n\\nMars is home to the tallest mountain in the solar system. Olympus Mons, a shield volcano, stands at a whopping 22 kilometers (13.6 miles) tall. This is almost three times taller than Mount Everest, the tallest mountain on Earth. ', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {}, 'model_name': 'gpt-3.5-turbo-instruct'}, run=None)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint (result.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "437ea59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ank = llm.generate(['Ankur Deshwal working in semiconducor industry is known for'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4173bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text=\" his unique talent of working with semiconductors. He is a master in designing, developing and implementing semiconductor devices and systems. He has a deep understanding of semiconductors and is able to create innovative solutions for various applications.\\n\\nAnkur's passion for semiconductors started during his college days when he was pursuing his Bachelor's degree in Electrical Engineering. He was fascinated by the intricacies of semiconductor devices and their potential to revolutionize the electronics industry. He decided to specialize in this field and pursued a Master's degree in Microelectronics.\\n\\nAfter completing his education, Ankur started working in the semiconductor industry and quickly made a name for himself. He has worked with some of the top companies in the industry and has been involved in various projects ranging from designing microchips for consumer electronics to developing advanced sensors for medical devices.\\n\\nAnkur's expertise lies in his ability to understand the complex physics behind semiconductors and use that knowledge to create efficient and reliable semiconductor devices. He has a keen eye for detail and is able to identify and solve problems quickly. His innovative approach and strong analytical skills have helped him develop cutting-edge solutions for various applications.\\n\\nApart from his technical skills, Ankur is also known for his leadership qualities. He has led several teams and has ment\", generation_info={'finish_reason': 'length', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 15, 'completion_tokens': 256, 'total_tokens': 271}, 'model_name': 'gpt-3.5-turbo-instruct'} run=[RunInfo(run_id=UUID('8dab81eb-f38d-4bb2-9bd4-ebfd28aeb775'))]\n"
     ]
    }
   ],
   "source": [
    "print (result_ank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0668e73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" his unique talent of working with semiconductors. He is a master in designing, developing and implementing semiconductor devices and systems. He has a deep understanding of semiconductors and is able to create innovative solutions for various applications.\\n\\nAnkur's passion for semiconductors started during his college days when he was pursuing his Bachelor's degree in Electrical Engineering. He was fascinated by the intricacies of semiconductor devices and their potential to revolutionize the electronics industry. He decided to specialize in this field and pursued a Master's degree in Microelectronics.\\n\\nAfter completing his education, Ankur started working in the semiconductor industry and quickly made a name for himself. He has worked with some of the top companies in the industry and has been involved in various projects ranging from designing microchips for consumer electronics to developing advanced sensors for medical devices.\\n\\nAnkur's expertise lies in his ability to understand the complex physics behind semiconductors and use that knowledge to create efficient and reliable semiconductor devices. He has a keen eye for detail and is able to identify and solve problems quickly. His innovative approach and strong analytical skills have helped him develop cutting-edge solutions for various applications.\\n\\nApart from his technical skills, Ankur is also known for his leadership qualities. He has led several teams and has ment\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ank.generations[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d37ccf-99d2-4aa6-ab73-0bd22e55b7b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Language Model Templates\n",
    "\n",
    "### No Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e34d990-cc7c-47f6-a191-854a575aabca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a fact'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# An example prompt with no input variables\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a fact\")\n",
    "no_input_prompt.format()\n",
    "# -> \"Tell me a fact.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be521325-8963-4505-8bf3-83b05e8a796a",
   "metadata": {},
   "source": [
    "### Single Input Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "361467f3-81d3-4553-9a22-1198f44598c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a fact about Mars.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example prompt with one input variable\n",
    "one_input_prompt = PromptTemplate(input_variables=[\"topic\"], template=\"Tell me a fact about {topic}.\")\n",
    "# Notice how the stirng \"topic\" gets automatically converted to a parameter name, very convienent! \n",
    "one_input_prompt.format(topic=\"Mars\")\n",
    "# -> \"Tell me a fact about Mars\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8c513-b8d0-4616-9015-e0133cfc45d4",
   "metadata": {},
   "source": [
    "### Multiple Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aba25263-4b12-40d8-8c56-e21b9bc37891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a fact about Mars for a student 8th Grade level.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example prompt with multiple input variables\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"level\"], \n",
    "    template=\"Tell me a fact about {topic} for a student {level} level.\"\n",
    ")\n",
    "multiple_input_prompt.format(topic='Mars',level='8th Grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d47473-7d74-4bbf-875e-898bc9cdb1ec",
   "metadata": {},
   "source": [
    "# Chat Model Templates\n",
    "\n",
    "Chat models require a list of chat messages called a prompt, which is different from a raw string that you would input into a language model. Each message in the prompt is associated with a role, such as AI, human, or system.\n",
    "\n",
    "For instance, when using the OpenAI Chat Completion API, a chat message can be assigned the role of AI, human, or system. The model is designed to pay closer attention to instructions provided in system chat messages.\n",
    "\n",
    "To simplify the process of constructing and working with prompts, LangChain offers various prompt templates. It is highly recommended to utilize these chat-related prompt templates instead of PromptTemplate when interacting with chat models. This will allow you to fully harness the potential of the underlying chat model and enhance your experience.\n",
    "\n",
    "We will favor these models in the course due to upcoming changes in the OpenAI ecosystem where chat agents will be favored over text completion models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1cbda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "923b8070-19ab-4972-89f0-57b6e56053fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4fbc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "native_prompt = PromptTemplate.from_template(\"You are an {language} coding expert great at writing recursive functions for everything\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c73c0945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language'] template='You are an {language} coding expert great at writing recursive functions for everything'\n"
     ]
    }
   ],
   "source": [
    "print (native_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14f27096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.base.BasePromptTemplate.Config"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_prompt.Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cbc8eeab-11ff-4c46-b69b-e963066980d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template=\"You are an {language} coding expert great at writing recursive functions for everything\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31ba7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['language'], template='You are an {language} coding expert great at writing recursive functions for everything')\n",
      "<class 'langchain_core.load.serializable.Serializable.Config'>\n"
     ]
    }
   ],
   "source": [
    "print (system_message_prompt)\n",
    "print (system_message_prompt.Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d93298f9-18d3-43af-bc23-633f5f3ab269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2348e5e3-e878-403a-94e9-be61359fbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template=\"{problem_statement}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d01b14b6-f422-4a08-bd0e-bba0f494563d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['problem_statement'], template='{problem_statement}'))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "706756df-1264-4121-8043-b733e60188c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "52fdf3cf-f3d9-4108-ae72-b630487d9e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language', 'problem_statement']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d810dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language', 'problem_statement'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='You are an {language} coding expert great at writing recursive functions for everything')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['problem_statement'], template='{problem_statement}'))]\n"
     ]
    }
   ],
   "source": [
    "print (chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b19ae01-3be8-41c9-a470-3fd6fc69e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an python coding expert great at writing recursive functions for everything'),\n",
       " HumanMessage(content='count number of nodes in binary tree')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a chat completion from the formatted messages\n",
    "chat_prompt.format_prompt(language=\"python\", problem_statement=\"count number of nodes in binary tree\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73121537-8cee-42fc-ba0e-fc1c18154957",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = chat_prompt.format_prompt(language=\"python\", problem_statement=\"count number of nodes in binary tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f92882ca-beb4-429b-ad73-d6850ea682d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "print (type(request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f739bc95-42c3-4c01-9f77-6dcfcc6ec21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an python coding expert great at writing recursive functions for everything\n",
      "Human: count number of nodes in binary tree\n"
     ]
    }
   ],
   "source": [
    "print (request.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43e55dd4-f863-4673-b297-2945af66d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are an python coding expert great at writing recursive functions for everything'), HumanMessage(content='count number of nodes in binary tree')]\n"
     ]
    }
   ],
   "source": [
    "print (request.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276622f-d81c-40ed-864b-63d4c4311d84",
   "metadata": {},
   "source": [
    "## Prompt Templates with an LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1496d66-efec-4cd5-a62e-d33f9669941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8978391d-9c09-4b99-8520-27491ece4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat(request.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88f47c1b-123c-4f47-8ee1-b72c88cbd048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='To count the number of nodes in a binary tree, we can use a recursive function that traverses through the tree and increments a counter for each node encountered.\\n\\nHere\\'s an example implementation:\\n\\n```python\\nclass Node:\\n    def __init__(self, value):\\n        self.value = value\\n        self.left = None\\n        self.right = None\\n\\ndef count_nodes(root):\\n    if root is None:\\n        return 0\\n\\n    return 1 + count_nodes(root.left) + count_nodes(root.right)\\n```\\n\\nIn this implementation, the `count_nodes` function takes the root node of the binary tree as input and returns the total number of nodes in the tree.\\n\\nWe start by checking if the root node is None. If it is, then the tree is empty and we return 0.\\n\\nIf the root node is not None, we increment the counter by 1 and recursively call the `count_nodes` function on both the left and right subtrees. The sum of the counts from the left and right subtrees, along with the root node, gives us the total number of nodes in the binary tree.\\n\\nHere\\'s an example usage:\\n\\n```python\\n# Create a binary tree\\nroot = Node(1)\\nroot.left = Node(2)\\nroot.right = Node(3)\\nroot.left.left = Node(4)\\nroot.left.right = Node(5)\\n\\n# Count the number of nodes\\nnum_nodes = count_nodes(root)\\nprint(\"Number of nodes:\", num_nodes)\\n```\\n\\nOutput:\\n```\\nNumber of nodes: 5\\n```\\n\\nIn this example, the binary tree has 5 nodes, including the root node.'\n"
     ]
    }
   ],
   "source": [
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ae9e58d-00b9-4ba4-af37-9ff35a4bef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To count the number of nodes in a binary tree, we can use a recursive function that traverses through the tree and increments a counter for each node encountered.\n",
      "\n",
      "Here's an example implementation:\n",
      "\n",
      "```python\n",
      "class Node:\n",
      "    def __init__(self, value):\n",
      "        self.value = value\n",
      "        self.left = None\n",
      "        self.right = None\n",
      "\n",
      "def count_nodes(root):\n",
      "    if root is None:\n",
      "        return 0\n",
      "\n",
      "    return 1 + count_nodes(root.left) + count_nodes(root.right)\n",
      "```\n",
      "\n",
      "In this implementation, the `count_nodes` function takes the root node of the binary tree as input and returns the total number of nodes in the tree.\n",
      "\n",
      "We start by checking if the root node is None. If it is, then the tree is empty and we return 0.\n",
      "\n",
      "If the root node is not None, we increment the counter by 1 and recursively call the `count_nodes` function on both the left and right subtrees. The sum of the counts from the left and right subtrees, along with the root node, gives us the total number of nodes in the binary tree.\n",
      "\n",
      "Here's an example usage:\n",
      "\n",
      "```python\n",
      "# Create a binary tree\n",
      "root = Node(1)\n",
      "root.left = Node(2)\n",
      "root.right = Node(3)\n",
      "root.left.left = Node(4)\n",
      "root.left.right = Node(5)\n",
      "\n",
      "# Count the number of nodes\n",
      "num_nodes = count_nodes(root)\n",
      "print(\"Number of nodes:\", num_nodes)\n",
      "```\n",
      "\n",
      "Output:\n",
      "```\n",
      "Number of nodes: 5\n",
      "```\n",
      "\n",
      "In this example, the binary tree has 5 nodes, including the root node.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ee656-ec4b-4c5b-b839-1b3c2f269f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
