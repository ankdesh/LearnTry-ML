{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import hyperopt.hp as hp\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, a, b):\n",
    "    return a * (x**2) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_hyper(config):\n",
    "    # config (dict): A dict of hyperparameters.\n",
    "\n",
    "    for x in range(20):\n",
    "        score = objective(x, config[\"a\"], config[\"b\"])\n",
    "\n",
    "        tune.report(score=score)  # This sends the score to Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"a\": hp.uniform(\"a\", 0, 1),\n",
    "    \"b\": hp.uniform(\"b\", 0, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-03 08:54:50,598\tINFO resource_spec.py:231 -- Starting Ray with 9.03 GiB memory available for workers and up to 4.54 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-09-03 08:54:51,134\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n",
      "2020-09-03 08:54:51,138\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67026944 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "2020-09-03 08:54:51,163\tWARNING services.py:1567 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67026944 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "2020-09-03 08:54:53,262\tWARNING tune.py:325 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n",
      "2020-09-03 08:54:53,292\tERROR syncer.py:46 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.8/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/4 CPUs, 0/1 GPUs, 0.0/9.03 GiB heap, 0.0/3.12 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/ankdesh/ray_results/trainable_hyper<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_hyper_21f92_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for trainable_hyper_21f92_00000:\n",
      "  date: 2020-09-03_08-54-53\n",
      "  done: false\n",
      "  experiment_id: b9a8ce11234248a1acd173c5272d516a\n",
      "  experiment_tag: '0'\n",
      "  hostname: ab778119f77d\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.2\n",
      "  pid: 16993\n",
      "  score: '0 add\n",
      "  \n",
      "    1   mul\n",
      "  \n",
      "    2     float\n",
      "  \n",
      "    3       hyperopt_param\n",
      "  \n",
      "    4         Literal{a}\n",
      "  \n",
      "    5         uniform\n",
      "  \n",
      "    6           Literal{0}\n",
      "  \n",
      "    7           Literal{1}\n",
      "  \n",
      "    8     Literal{0}\n",
      "  \n",
      "    9   float\n",
      "  \n",
      "    10     hyperopt_param\n",
      "  \n",
      "    11       Literal{b}\n",
      "  \n",
      "    12       uniform\n",
      "  \n",
      "    13         Literal{0}\n",
      "  \n",
      "    14         Literal{20}'\n",
      "  time_since_restore: 0.0004515647888183594\n",
      "  time_this_iter_s: 0.0004515647888183594\n",
      "  time_total_s: 0.0004515647888183594\n",
      "  timestamp: 1599123293\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 21f92_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16993)\u001b[0m 2020-09-03 08:54:53,860\tWARNING function_runner.py:503 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/1 GPUs, 0.0/9.03 GiB heap, 0.0/3.12 GiB objects (0/1.0 GPUType:GTX)<br>Result logdir: /home/ankdesh/ray_results/trainable_hyper<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainable_hyper_21f92_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">       0.0715373</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    trainable_hyper,\n",
    "    config=space,\n",
    "    num_samples=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best config:  None\n"
     ]
    }
   ],
   "source": [
    "print(\"best config: \", analysis.get_best_trial(metric=\"score\", mode=\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print (analysis.get_best_config(metric=\"score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
